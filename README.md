# Nerfstudio Batch Processing Array

SLURM-based scripts for automating NeRF training and pose inspection workflows using Nerfstudio.

## üîß Folder Structure

```
nerf_scripts/
‚îú‚îÄ‚îÄ end2end_nerf_reconstruction/
‚îÇ   ‚îú‚îÄ‚îÄ run_nerfstudio_array.sh
‚îÇ   ‚îî‚îÄ‚îÄ job_array_train_preset_intrinsics.sh
‚îÇ   ‚îî‚îÄ‚îÄ video_list.txt
‚îú‚îÄ‚îÄ pose_estimation_checking/
‚îÇ   ‚îú‚îÄ‚îÄ camera_pose_display_used_in_bash.py
‚îÇ   ‚îú‚îÄ‚îÄ job_array_pose_estimation.sh
‚îÇ   ‚îî‚îÄ‚îÄ video_list.txt
```

---

## üöÄ Quick Start: End-to-End NeRF Reconstruction

1. **List videos**

   ```bash
   find /path/to/videos -type f \( -iname "*.mp4" -o -iname "*.mov" -o -iname "*.avi" -o -iname "*.mkv" \) > end2end_nerf_reconstruction/video_list.txt
   ```

2. **Run SLURM job**

   ```bash
   cd end2end_nerf_reconstruction
   chmod +x run_nerfstudio_array.sh
   sbatch run_nerfstudio_array.sh
   ```

3. **Output Logs**

   * `logs/array_train_<JOBID>_<TASKID>.out` ‚Äì stdout
   * `logs/array_train_<JOBID>_<TASKID>.err` ‚Äì stderr

---

## üß† What It Does

### `run_nerfstudio_array.sh` (in `end2end_nerf_reconstruction/`)

Automates per-video processing via a SLURM array:

* **Environment Setup**: Loads CUDA and activates Nerfstudio conda env
* **Video Selection**: Indexes `video_list.txt` using `$SLURM_ARRAY_TASK_ID`
* **Rotation**: Uses `ffmpeg` to rotate last 20s of each clip
* **Preprocessing**: Runs `ns-process-data` to extract frames (\~70)
* **Training**: Uses `ns-train nerfacto` with 30,000 iters
* **Export**:

  * `ns-export pointcloud` ‚Üí `pcd/<basename>_colmap_pcd/pointcloud/`
  * `ns-export poisson` ‚Üí `pcd/<basename>_colmap_pcd/poisson/`

---

## üìÅ Output Structure

* `processed/<basename>_colmap/` ‚Äì COLMAP outputs
* `pcd/<basename>_colmap_pcd/pointcloud/` ‚Äì point clouds (.ply)
* `pcd/<basename>_colmap_pcd/poisson/` ‚Äì meshes (.ply)

---
## ‚öôÔ∏è Parameters to Tune
Adjust values as needed for your test or full run.  
* `ffmpeg` rotation: `-sseof -20` (last 20s), `transpose=1` (orientation) 
* Frame extraction: `--num-frames-target 70`
* SLURM array range: `#SBATCH --array=0-N`

## üîç Pose Estimation Checking

Folder: `pose_estimation_checking/`

Tools to inspect and compare COLMAP camera pose estimation results using different settings.

### üìÇ Contents

* `camera_pose_display_used_in_bash.py` ‚Äì Visualizes or parses COLMAP pose outputs (can be used in scripts or interactively).
* `job_array_pose_estimation.sh` ‚Äì SLURM array script for processing multiple videos with various COLMAP settings.
* `video_list.txt` ‚Äì List of input video paths (generated manually).

### üöÄ Quick Start

1. **List videos**

   ```bash
   find /path/to/videos -type f \( -iname "*.mp4" -o -iname "*.mov" -o -iname "*.avi" -o -iname "*.mkv" \) > pose_estimation_checking/video_list.txt
   ```

2. **Run SLURM Job**

   ```bash
   cd pose_estimation_checking
   chmod +x job_array_pose_estimation.sh
   sbatch job_array_pose_estimation.sh
   ```

### üß† What It Does

The script:

* Selects videos from `video_list.txt` using `$SLURM_ARRAY_TASK_ID`
* Runs `ns-process-data` on each video using different COLMAP settings (e.g., with/without `--use-colmap-default-intrinsics`, etc.)
* Logs the COLMAP console output
* Extracts estimated camera poses (extrinsics) to a dedicated folder
* Visualizes the camera trajectories using `camera_pose_display_used_in_bash.py`

### üìå Goal

To **compare different COLMAP settings** on your video dataset:

* Evaluate which settings produce the most accurate and stable camera poses
* Use visualizations and logs to guide selection of settings for NeRF training

